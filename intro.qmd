# Introduction

# Curriculum

**Foundations**: This part of the course lays the groundwork for everything that follows. It delves into the essential theories and foundational knowledge necessary for constructing AI systems, including an introduction to AI and machine learning and covering the crucial mathematical and statistical theories needed to grasp these areas. Furthermore, it introduces the fundamentals of software engineering, cloud computing, and system architecture concepts related to designing and developing end-to-end ML systems. A  Python programming refresher will also be provided.

**Documenting and initiating ML projects**:  Like any software solution, ML systems require a well-structured methodology to ensure high success rates. The challenge often lies not in the ML algorithms themselves but in integrating these algorithms with the rest of the software and hardware components of the system to solve real-world problems. It's noted that 60 out of 96 failures are due to non-ML components, and 60% of models never reach production. This section provides a guide to initiating and documenting AI projects, discusses some challenges encountered in AI system development, and provides a guide for building AI systems. 

**Creating and leading Machine Learning Teams**: Machine Learning talents are expensive and scarce, and machine Learning teams have diverse roles. Managing and leading ML and Data Science teams require unique skills. Here, we will learn more about some of the most common ML team structures and the importance and impact of each role.

<!-- 2. **ML system design and architecture foundations**: The design and architecture of ML systems are critical to the success of AI projects. This section will discuss some of the best practices for designing and architecting ML systems, including the use of microservices, containers, and orchestration tools. It will also discuss how to select the appropiate architecture for ML systems, including centralized, decentralized, and hybrid architectures. -->

**Defining the stack technology for your ML System**: The number of available tools to develop ML systems for production seems endless. Choosing the right tools depends on various factors, such as the problem being tackled, the type of solution required, deployment scenario, team experience, capacity building, cost, hardware and software infrastructure, and more. As an ML engineer, it is essential to familiarize yourself with the ecosystem of tools and be able to select the most appropriate ones for the problem at hand. In this section, we'll explore different tools used in production for designing, developing, and implementing ML systems and how they can be integrated.


**Data Management strategies for ML projects**: Data is the most important asset in AI systems. The quality of the data will determine the quality of the model. This section will discuss the best practices for managing data in AI systems, including data collection, data cleaning, data storage, and data processing. It will also discuss how to select the appropiate data management tools for data storage, data processing, and data visualization.

**Training debuging and desin patterns for ML solutions**: This section will discuss the best practices for training ML models, including data preprocessing, model selection, model training, and model evaluation. It will also discuss how to debug ML models and how to use design patterns to build scalable and maintainable ML systems.Design patterns capture best practices and solutions to commonly occurring problems. They codify the knowledge and experience of experts into advice that all practitioners can follow.

**Deployment ML system in production**: 
A machine learning model can only begin to add value to an organization when that model's insights routinely become available to the users for which it was built. The process of taking a trained ML model and making its predictions available to users or other systems is known as deployment. Let's learn together about troubleshooting and deploying ML models in production and how we can ship ML models to production using different deployments strategies and scenarios.

**ML operation: DevOps -> MLOps -> LLMOps -> FMOps:** The development of ML systems is a complex process that requires the collaboration of different teams, including data scientists, software engineers, and operations teams. This section will discuss the challenges of integrating ML models into production systems and the best practices for managing ML models in production. MLOps is a methodology for ML engineering that unifies ML system development (the ML element) with ML system operations (the Ops element). It advocates formalizing and (when beneficial) automating critical steps of ML system construction. This course will discuss how MLOps maximize the capacities and resources of ML teams by providing a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably
